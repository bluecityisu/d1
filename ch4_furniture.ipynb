{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch4_furniture.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Rb-5IZZ3LtW-IxbF-Xu4xalux8PDu32Y",
      "authorship_tag": "ABX9TyPVPjZNQ7h6LtNDh0Z4TF05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluecityisu/d1/blob/main/ch4_furniture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNFV-Fecf37v"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "from keras import models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, GlobalAveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "batchsize = 10\n",
        "NUM_EPOCHS = 10\n",
        "img_width, img_height = 150, 150\n",
        "#for VGG 16 use 224 image size\n",
        "#img_width, img_height = 224, 224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = r'/content/drive/MyDrive/TensorFlow_Book/masterVision/dataset/furniture-images/img/train'\n",
        "val_dir = r'/content/drive/MyDrive/TensorFlow_Book/masterVision/dataset/furniture-images/img/val'\n",
        "\n",
        "train_bed_dir = os.path.join(train_dir, 'bed') \n",
        "train_chair_dir = os.path.join(train_dir, 'chair')  \n",
        "train_sofa_dir = os.path.join(train_dir, 'sofa') \n",
        "val_bed_dir = os.path.join(val_dir, 'bed')  \n",
        "val_chair_dir = os.path.join(val_dir, 'chair')  \n",
        "val_sofa_dir = os.path.join(val_dir, 'sofa')  "
      ],
      "metadata": {
        "id": "Hn93DplCgLlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_bed_train = len(os.listdir(train_bed_dir))\n",
        "num_chair_train = len(os.listdir(train_chair_dir))\n",
        "num_sofa_train = len(os.listdir(train_sofa_dir))\n",
        "\n",
        "num_bed_val = len(os.listdir(val_bed_dir))\n",
        "num_chair_val = len(os.listdir(val_chair_dir))\n",
        "num_sofa_val = len(os.listdir(val_sofa_dir))\n",
        "\n",
        "num_train_images = num_bed_train + num_chair_train + num_sofa_train\n",
        "num_val_images = num_bed_val + num_chair_val + num_sofa_val\n",
        "print(num_train_images, num_val_images)"
      ],
      "metadata": {
        "id": "zRimxmrfgoRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, \n",
        "                                                    target_size=(img_height, img_width), \n",
        "                                                    batch_size=batchsize)"
      ],
      "metadata": {
        "id": "41F-jzQKgxOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(val_dir, \n",
        "                                                    target_size=(img_height, img_width), \n",
        "                                                    batch_size=batchsize)"
      ],
      "metadata": {
        "id": "FZWUr1-ug0zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rL3LllHHhAb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(64, (3,3), activation='relu', input_shape=(img_height, img_width ,3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "E3G0eNjzhDQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = Adam(lr=0.00001)\n",
        "model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9OPeylIHifgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PQcVJVgWiogu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,epochs=NUM_EPOCHS,steps_per_epoch=num_train_images // batchsize,validation_data=val_generator, validation_steps=num_val_images // batchsize)\n"
      ],
      "metadata": {
        "id": "G6vuf9yRiugF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.layers))"
      ],
      "metadata": {
        "id": "BNGTJbPbry8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#img_path = r'/content/drive/MyDrive/TensorFlow_Book/masterVision/dataset/furniture-images/img/val/chair/00000015.jpg'\n",
        "#img_path = r'/content/drive/MyDrive/TensorFlow_Book/masterVision/dataset/furniture-images/img/val/bed/00000902.jpg'\n",
        "img_path = r'/content/drive/MyDrive/TensorFlow_Book/masterVision/dataset/furniture-images/img/val/sofa/00000210.jpg'\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor1 = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor2 = preprocess_input(img_tensor1)\n",
        "\n",
        "featuremap = model.predict(img_tensor2)\n",
        "plt.imshow(img)\n",
        "#plt.imshow(featuremap)\n",
        "print(featuremap.argmax())\n",
        "#plt.imshow(img_tensor2[0])\n",
        "#print (img_tensor.shape)"
      ],
      "metadata": {
        "id": "2whC9-A1r5OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "layer_outputs = [layer.output for layer in model.layers[:len(model.layers)]]\n",
        "activation_modelfig = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activationsfig = activation_modelfig.predict(img_tensor2)"
      ],
      "metadata": {
        "id": "CFGyPGCYxe66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_layer_activation = activationsfig[0]\n",
        "print(first_layer_activation.shape)\n",
        "plt.matshow(first_layer_activation[0, :, :, 2], cmap='viridis')"
      ],
      "metadata": {
        "id": "zvYUNWuGxlx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(model.layers)-8):\n",
        "    current_layer_activation = activationsfig[i]\n",
        "    ns = current_layer_activation.shape[-1]\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(current_layer_activation[0, :, :, 0], cmap='viridis')\n",
        "    \n",
        "    ax3 = fig.add_subplot(132)\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(current_layer_activation[0, :, :, int(ns/2)], cmap='viridis')\n",
        "    \n",
        "    ax5 = fig.add_subplot(133)\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(current_layer_activation[0, :, :, ns-1], cmap='viridis')\n",
        "    "
      ],
      "metadata": {
        "id": "FtgCsPqMxqxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}